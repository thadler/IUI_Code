{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_reader\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2submits  = 'iui20_ideaSubmitsPart2.csv'\n",
    "path2requests = 'iui20_inspirationRequestsPart2.csv'\n",
    "seconds_per_bucket = 60\n",
    "train_percentage = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data as sessions\n",
    "sessions = data_reader.load_data_as_sessions_dict(path2submits, path2requests, seconds_per_bucket)\n",
    "# calculate avoiders and seekers\n",
    "sessions = data_reader.add_avoiders_and_seekers(sessions)\n",
    "# create train and test set of worker ids\n",
    "train_worker_ids, test_worker_ids = data_reader.split_worker_ids_into_train_test(sessions, train_percentage=train_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through different numbers of buckets\n",
    "# train a classifier for each different numbers of buckets\n",
    "# test on test examples\n",
    "# get roc curve\n",
    "conf_matrices = []\n",
    "max_number_of_buckets = 15\n",
    "for nr_of_buckets in range(1, max_number_of_buckets):\n",
    "    x_tr, y_tr, x_te, y_te = data_reader.create_train_test_dataset(nr_of_buckets, train_worker_ids, test_worker_ids, sessions, train_percentage)\n",
    "    #clf = DecisionTreeClassifier()\n",
    "    clf = RandomForestClassifier(200)\n",
    "    clf.fit(x_tr, y_tr)\n",
    "    y_pre = clf.predict(x_te)\n",
    "    conf_matrices.append(confusion_matrix(y_te, y_pre))\n",
    "\n",
    "# [[tn, fp, fn, tp], ...]\n",
    "conf_matrices = np.array([conf_m.ravel() for conf_m in conf_matrices])\n",
    "accuracies = [(cm[0]+cm[3])/sum(cm) for cm in conf_matrices]\n",
    "precisions = [cm[3]/(cm[3]+cm[1])   for cm in conf_matrices]\n",
    "recall     = [cm[3]/(cm[3]+cm[2])   for cm in conf_matrices]\n",
    "\n",
    "print(conf_matrices)\n",
    "\n",
    "plt.plot(accuracies, label='accuracy')\n",
    "plt.plot(precisions, label='precision')\n",
    "plt.plot(recall,     label='recall')\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=3, mode=\"expand\", borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "\n",
    "train_percentage = 1.0\n",
    "nr_of_buckets = 10\n",
    "x_tr, y_tr, x_te, y_te = data_reader.create_train_test_dataset(nr_of_buckets, train_worker_ids, test_worker_ids, sessions, train_percentage)\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(x_tr, y_tr)\n",
    "    \n",
    "dot_data = StringIO()\n",
    "export_graphviz(clf, out_file=dot_data, filled=True, rounded=True, special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
